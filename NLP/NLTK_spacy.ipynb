{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "261af02e",
   "metadata": {},
   "source": [
    "# Natural Language Processing: NLTK vs spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39badbe",
   "metadata": {},
   "source": [
    "NLTK is essentially a string processing library, where each function takes strings as input and returns a processed string.\n",
    "spaCy takes an object-oriented approach. Each function returns objects instead of strings or arrays. This allows for easy \n",
    "exploration of the tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748036aa",
   "metadata": {},
   "source": [
    "Each library utilizes either time or space to improve performance. While NLTK returns results much slower than \n",
    "spaCy (spaCy is a memory hog!), spaCyâ€™s performance is attributed to the fact that it was written in Cython from \n",
    "the ground up.\n",
    "\n",
    "Most sources on the Internet mention that spaCy only supports the English language, but these articles were written \n",
    "a few years ago. Since then, spaCy has grown to support over 50 languages. Both spaCy and NLTK support English, German, \n",
    "French, Spanish, Portuguese, Italian, Dutch, and Greek."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec8ec3",
   "metadata": {},
   "source": [
    "# Part-of-speech tagging - NLTK allows to determine the grammatical parts of speech for each word in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0641e74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized words: ['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'NLP', '.', 'It', 'makes', 'natural', 'language', 'processing', 'simple', '.']\n",
      "Tokenized sentences: ['NLTK is a powerful library for NLP.', 'It makes natural language processing simple.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SONY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "nltk.download('punkt')  # Download the Punkt tokenizer models\n",
    "\n",
    "text = \"NLTK is a powerful library for NLP. It makes natural language processing simple.\"\n",
    "\n",
    "# Tokenize into words\n",
    "words = word_tokenize(text)\n",
    "print(\"Tokenized words:\", words)\n",
    "\n",
    "# Tokenize into sentences\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"Tokenized sentences:\", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459a13c4",
   "metadata": {},
   "source": [
    "# Part-of-speech tagging - NLTK allows you to determine the grammatical parts of speech for each word in a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f93e4bf",
   "metadata": {},
   "source": [
    "In this example, the pos_tag function from NLTK is used to assign a part-of-speech tag to each word in the input text. \n",
    "The result is then printed, showing each word along with its corresponding part-of-speech tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21eb85b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part-of-Speech tagging result:\n",
      "NLTK: NNP\n",
      "is: VBZ\n",
      "a: DT\n",
      "powerful: JJ\n",
      "library: NN\n",
      "for: IN\n",
      "natural: JJ\n",
      "language: NN\n",
      "processing: NN\n",
      ".: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SONY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\SONY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "nltk.download('punkt')  # Download the Punkt tokenizer models\n",
    "nltk.download('averaged_perceptron_tagger')  # Download the POS tagger model\n",
    "\n",
    "text = \"NLTK is a powerful library for natural language processing.\"\n",
    "\n",
    "# Tokenize the text\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Perform Part-of-Speech tagging\n",
    "pos_tags = pos_tag(words)\n",
    "\n",
    "# Display the Part-of-Speech tagged result\n",
    "print(\"Part-of-Speech tagging result:\")\n",
    "for word, pos_tag in pos_tags:\n",
    "    print(f\"{word}: {pos_tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f6b20",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER) - spaCy excels in identifying entities like names, locations, and organizations within a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7db783e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities: [('Apple Inc.', 'ORG'), ('Steve Jobs', 'PERSON'), ('Cupertino', 'GPE'), ('California', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "text = \"Apple Inc. was founded by Steve Jobs. It is headquartered in Cupertino, California.\"\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract named entities\n",
    "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "print(\"Named Entities:\", entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785e3bec",
   "metadata": {},
   "source": [
    "# Dependency parsing - spaCy helps in understanding the grammatical structure of sentences, highlighting relationships between words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b43a68",
   "metadata": {},
   "source": [
    "In this example, the spaCy model is loaded, and a sample sentence is processed. The dep_ attribute of each token provides \n",
    "information about its dependency relation to the head token (parent) in the sentence. The output shows the relationships \n",
    "between words in the form of a dependency parse tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3742a888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency Parse Tree:\n",
      "SpaCy --nsubj--> helps\n",
      "helps --ROOT--> helps\n",
      "in --prep--> helps\n",
      "understanding --pcomp--> in\n",
      "the --det--> structure\n",
      "grammatical --amod--> structure\n",
      "structure --dobj--> understanding\n",
      "of --prep--> structure\n",
      "sentences --pobj--> of\n",
      ". --punct--> helps\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Example sentence\n",
    "sentence = \"SpaCy helps in understanding the grammatical structure of sentences.\"\n",
    "\n",
    "# Process the sentence\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Display the dependency parse tree\n",
    "print(\"Dependency Parse Tree:\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} --{token.dep_}--> {token.head.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73487e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
