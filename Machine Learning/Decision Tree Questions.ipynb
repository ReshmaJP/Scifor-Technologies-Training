{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c922d7c",
   "metadata": {},
   "source": [
    "# Q1. Describe the decision tree classifier algorithm and how it works to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85832e",
   "metadata": {},
   "source": [
    "Decision tree classifier is a supervised learning algorithm. It can be used for both classification and regression problems.\n",
    "Its objective is to create a training model that can use to predict the class or value of the target variable by learning the\n",
    "simple decision rules from prior data. It realises the problem and takes the decision based on the answers to every conditions.\n",
    "It uses a tree structure to show all the positive outcome of a decision. \n",
    "\n",
    "It consist of Root node, Decision node and Leaf node:\n",
    "Root node - Main node\n",
    "Decision node - It specify a certain condition\n",
    "Leaf node - It is used for execution according to their results (output nodes)\n",
    "\n",
    "Decision Tree is good to handle large dataset. Directly gives the outcome Yes/No\n",
    "Less cleaning is required.\n",
    "\n",
    "Entropy, Information Gain, and Gini Index are three commonly used metrics in decision tree algorithms for evaluating the \n",
    "quality of a split (node) in the dataset. These metrics help the algorithm decide which feature to split on at each node \n",
    "to create an effective decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09193cb5",
   "metadata": {},
   "source": [
    "# Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5b2c64",
   "metadata": {},
   "source": [
    "Entropy, Information Gain, and Gini Index are three commonly used metrics in decision tree algorithms for evaluating the \n",
    "quality of a split (node) in the dataset. These metrics help the algorithm decide which feature to split on at each node to \n",
    "create an effective decision tree.\n",
    "\n",
    "There are two types of split, impure split and pure split. This is checked using the measure of purity which is Entropy and\n",
    "Gini Index. \n",
    "\n",
    "Entropy - Measures the uncertainity of a set of data. It is used to determine how well a tree is splitting the data into\n",
    "classes.\n",
    "E = - Summation(i = 1 to n) Pi log2 (Pi); Pi - Probability of yes and no, it could be P+ (Probability of Yes) and P-\n",
    "(Probability of No)\n",
    "\n",
    "Gini Index - It measures the probability for a misclassified instance\n",
    "GI = 1 - summation(i = 1 to j)P(i)^2 ; Pi - Probability of yes and no, it could be P+ (Probability of Yes) and P-\n",
    "(Probability of No)\n",
    "\n",
    "Information Gain - It is used to measure the effectiveness of splitting a adatset based on the attribute. The attribute with \n",
    "highest IG is chosen as root node. It is the diiference between the entrop of before split and expected entropy after split.\n",
    "IG = Entropy (parent) - Entropy (Child)\n",
    "\n",
    "Examples:\n",
    "If f1 is parent node with 6yes/3no, c1 and c2 are child nodes with 3yes/3no and 3yes/0no. \n",
    "\n",
    "For C1,\n",
    "Entropy can be calculated as,\n",
    "P(yes) = 3/6 = 0.5\n",
    "P(no) = 3/6 = 0.5\n",
    "\n",
    "H(s) = - Summation(i = 1 to n) Pi log2 (Pi) = -(0.5(-1) + 0.5(-1)) = 1\n",
    "\n",
    "Gini Index can be calculated as,\n",
    "GI = 1 - summation(i = 1 to j)P(i)^2 = 1 - (P(yes)^2 + P(no)^2) = 1 - (0.25 + 0.25) = 0.5\n",
    "\n",
    "For C2,\n",
    "Entropy can be calculated as,\n",
    "P(yes) = 3/3 = 1.0\n",
    "P(no) = 0/3 = 0.0\n",
    "\n",
    "H(s) = - Summation(i = 1 to n) Pi log2 (Pi) = -(0.0 + 0.0) = 0\n",
    "\n",
    "Gini Index can be calculated as,\n",
    "GI = 1 - summation(i = 1 to j)P(i)^2 = 1 - (P(yes)^2 + P(no)^2) = 1 - (1.0 + 0.0) = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64870fc3",
   "metadata": {},
   "source": [
    "# Q3. Explain how a decision tree classifier can be used to solve a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "85dc6aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "10a6ed50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>1.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B  1  1.1  1.2  1.3\n",
       "0  R  1    1    1    2\n",
       "1  R  1    1    1    3\n",
       "2  R  1    1    1    4\n",
       "3  R  1    1    1    5\n",
       "4  R  1    1    2    1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset (xls file) to python environment\n",
    "data = pd.read_csv(\"C:/Users/SONY/Downloads/Python/balance-scale.data\", sep = ',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "10d90cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B      0\n",
       "1      0\n",
       "1.1    0\n",
       "1.2    0\n",
       "1.3    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eeecaac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test datasets\n",
    "X = data.drop(['B'], axis=1)\n",
    "y = data['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c6147f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "21b3f773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.7127659574468085\n",
      "Micro Precision: 0.71\n",
      "Micro Recall: 0.71\n",
      "Micro F1-score: 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier(criterion = 'gini', random_state=42, max_depth=3, min_samples_leaf=5)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "Y_pred = dt_model.predict(X_test)\n",
    "print('Accuracy is:', accuracy_score(y_test, Y_pred))\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_test, Y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_test, Y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}'.format(f1_score(y_test, Y_pred, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2de89b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  7,  5],\n",
       "       [ 0, 60, 27],\n",
       "       [ 0, 15, 74]], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "34dd794c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.00      0.00      0.00        12\n",
      "           L       0.73      0.69      0.71        87\n",
      "           R       0.70      0.83      0.76        89\n",
      "\n",
      "    accuracy                           0.71       188\n",
      "   macro avg       0.48      0.51      0.49       188\n",
      "weighted avg       0.67      0.71      0.69       188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SONY\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SONY\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SONY\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7fac8d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target\n",
    "target = list(data['B'].unique())\n",
    "feature_names = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bbd3855d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- 1 <= 2.50\n",
      "|   |--- 1.3 <= 2.50\n",
      "|   |   |--- 1.2 <= 2.50\n",
      "|   |   |   |--- class: L\n",
      "|   |   |--- 1.2 >  2.50\n",
      "|   |   |   |--- class: R\n",
      "|   |--- 1.3 >  2.50\n",
      "|   |   |--- 1.2 <= 1.50\n",
      "|   |   |   |--- class: R\n",
      "|   |   |--- 1.2 >  1.50\n",
      "|   |   |   |--- class: R\n",
      "|--- 1 >  2.50\n",
      "|   |--- 1.1 <= 2.50\n",
      "|   |   |--- 1.2 <= 1.50\n",
      "|   |   |   |--- class: L\n",
      "|   |   |--- 1.2 >  1.50\n",
      "|   |   |   |--- class: R\n",
      "|   |--- 1.1 >  2.50\n",
      "|   |   |--- 1.3 <= 3.50\n",
      "|   |   |   |--- class: L\n",
      "|   |   |--- 1.3 >  3.50\n",
      "|   |   |   |--- class: L\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create tree\n",
    "from sklearn.tree import export_text\n",
    "r=export_text(dt_model, feature_names=feature_names)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c63789",
   "metadata": {},
   "source": [
    "# Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386bf71c",
   "metadata": {},
   "source": [
    "Higher the value of information gain and lower value of Entropy and Gini Index gives a better performance in Decision Tree\n",
    "Classifier. Based on the probability of positive and negative outcomes measuring is calculated. Pruning is a technique used to\n",
    "reduces the size of decision trees by removing parts of the tree that do not provide power to classify instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f80fbfd",
   "metadata": {},
   "source": [
    "# Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1094d1e1",
   "metadata": {},
   "source": [
    "It is N*N matrix that gives the summary of the correct and incorrect predicted classification results for the N target classes.\n",
    "The values in the diagonal of the matrix represents the number of correctly predicted classes while every other cell in the\n",
    "matrix indictes the misclassified classes.\n",
    " \n",
    "               Actual - Positive  Actual - Nagative\n",
    "\n",
    "Predicted - Positive         TP                        FP\n",
    "\n",
    "--------------------------------------------------------------\n",
    "\n",
    "Predicted - Negative         FN                        TN\n",
    "\n",
    "\n",
    "It can be used to calculate Accuracy, Precision, Recall and F1 score.\n",
    "\n",
    "Accuracy = TP+TN/TP+TN+FP+FN;\n",
    "Precision = TP/TP+FP;\n",
    "Recall = TP/TP+FN;\n",
    "F1 score = 2 * (Precision * Recall)/(precision + Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ce9def",
   "metadata": {},
   "source": [
    "# Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be calculated from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6dbdab",
   "metadata": {},
   "source": [
    "Accuracy = TP+TN/TP+TN+FP+FN; Precision = TP/TP+FP; Recall = TP/TP+FN; F1 score = 2 * (Precision * Recall)/(precision + Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "89f04952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  7,  5],\n",
       "       [ 0, 60, 27],\n",
       "       [ 0, 15, 74]], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From the above example balance-scale\n",
    "\n",
    "#Confusion Matrix\n",
    "confusion_matrix(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5d97581a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.00      0.00      0.00        12\n",
      "           L       0.73      0.69      0.71        87\n",
      "           R       0.70      0.83      0.76        89\n",
      "\n",
      "    accuracy                           0.71       188\n",
      "   macro avg       0.48      0.51      0.49       188\n",
      "weighted avg       0.67      0.71      0.69       188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SONY\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SONY\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SONY\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56868fd3",
   "metadata": {},
   "source": [
    "# Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and explain how this can be done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff7e64b",
   "metadata": {},
   "source": [
    "Accuracy is common but may not be suitable for imbalanced datasets. Precision, recall, F1 score offer a more nuanced \n",
    "understanding of model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98476e96",
   "metadata": {},
   "source": [
    "# Q8. Provide an example of a classification problem where precision is the most important metric, and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d084496",
   "metadata": {},
   "source": [
    "Precision is the ratio of correctly predicted instances of a class to the total number of items predicted by the model \n",
    "to be in that class.\n",
    "Precision = TP/TP+FP\n",
    "\n",
    "Example: In a dataset it consist of 15 Emails. From that 10 Emails have been classified as spam. But actually only 7 were \n",
    "spam mails and rest Emails were not spam. Then Precision would be 7/10 and Recall would be 7/15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7240666",
   "metadata": {},
   "source": [
    "# Q9. Provide an example of a classification problem where recall is the most important metric, and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14de1d1",
   "metadata": {},
   "source": [
    "Recall  is the ratio of the true positives to the actual number of positives. It gives a total relevant results correctly\n",
    "predicted by the model.\n",
    "\n",
    "Example: In a medical diagnosis for a rare disease, recall is crucial because missing a positive case can have severe \n",
    "consequences, even if it means more false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb444b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
