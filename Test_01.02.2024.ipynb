{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75071155",
   "metadata": {},
   "source": [
    "# 1. What you understand by Text Processing? Write a code to perform text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9614b1ec",
   "metadata": {},
   "source": [
    "Text processing is one of the most common tasks used in machine learning applications such as language translation, sentiment \n",
    "analysis, spam filtering, and many others. Text processing refers to only the analysis, manipulation, and generation of text, \n",
    "while natural language processing refers to the ability of a computer to understand human language in a valuable way. \n",
    "Basically, natural language processing is the next step after text processing.\n",
    "\n",
    "Applications are,\n",
    "Topic analysis – This technique interprets and categorizes large collections of text into topics or themes.\n",
    "\n",
    "Sentiment analysis – This function automatically detects the emotional undertones of text and classifies them as positive, negative, or neutral.\n",
    "\n",
    "Language classification – This classifies text based on which language it’s written in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75370a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized words: ['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'NLP', '.', 'It', 'makes', 'natural', 'language', 'processing', 'simple', '.']\n",
      "Tokenized sentences: ['NLTK is a powerful library for NLP.', 'It makes natural language processing simple.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SONY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "nltk.download('punkt')  # Download the Punkt tokenizer models\n",
    "\n",
    "text = \"NLTK is a powerful library for NLP. It makes natural language processing simple.\"\n",
    "\n",
    "# Tokenize into words\n",
    "words = word_tokenize(text)\n",
    "print(\"Tokenized words:\", words)\n",
    "\n",
    "# Tokenize into sentences\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"Tokenized sentences:\", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfaf4f3",
   "metadata": {},
   "source": [
    "# 2. What you understand by NLP toolkit and spacy library? Write a code in which any one gets used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd35ce4",
   "metadata": {},
   "source": [
    "NLTK and spaCy are two of the most popular Natural Language Processing (NLP) tools available in Python. NLTK is a string \n",
    "processing library, where each function takes strings as input and returns a processed string. spaCy takes an object-oriented \n",
    "approach. Each function returns objects instead of strings or arrays. This allows for easy exploration of the tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a06948",
   "metadata": {},
   "source": [
    "Example: Tokenization - NLTK\n",
    "The term tokenization means to split a sentence or paragraph into its constituent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94758853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLTK',\n",
       " 'and',\n",
       " 'spaCy',\n",
       " 'are',\n",
       " 'two',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'popular',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'tools',\n",
       " 'available',\n",
       " 'in',\n",
       " 'Python',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "str = 'NLTK and spaCy are two of the most popular Natural Language Processing (NLP) tools available in Python.'\n",
    "nltk.word_tokenize(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf7aac",
   "metadata": {},
   "source": [
    "# 3. Describe Neural Networks and Deep Learning in Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfde93d",
   "metadata": {},
   "source": [
    "Overview of Neural Network\n",
    "\n",
    "●\tA neural network is formed when a collection of nodes or neurons are interlinked through synaptic connections \n",
    "●\tThere are three layers in every artificial neural network – input layer, hidden layer, and output layer\n",
    "●\tThe input layer that is formed from a collection of several nodes or neurons receives inputs\n",
    "●\tEvery neuron in the network has a function, and every connection has a weight value associated with it\n",
    "●\tInputs then move from the input layer to layer made from a separate set of neurons – the hidden layer\n",
    "●\tThe output layer gives the final outputs\n",
    "\n",
    "Activation Function: A neuron can be activated or not, it is determined by an activation function. The activation function calculates a weighted sum and further adds bias with it to give the result.\n",
    "\n",
    "Types of activation functions are:\n",
    "1. Sigmoid\n",
    "2. ReLU\n",
    "3. Softmax\n",
    "\n",
    "Optimizers: It plays a crucial role in training models. It adjusts the model parameters during training to minimize the loss function. The choice of optimizer can impact the convergence speed and the final performance of the model.\n",
    "\n",
    "Commonly used optimizer is: Adaptive Moment Estimation (Adam) is popular optimization algorithm that combines ideas from two other optimizers i.e. RMSprop and Momentum. When training a model, the objective is to minimize a loss function by adjusting the model’s parameters. This process involves finding the optimal set of parameters that results in the lowest possible loss. Optimizers automate this process by iteratively adjusting the parameters based on the gradients of the loss function with respect to those parameters.\n",
    "\n",
    "Deep Learning Algorithm - YOLO\n",
    "YOLO (You Only Look Once) is a popular object detection algorithm in deep learning. It's known for its real-time object detection capabilities and has been widely used in various applications, including computer vision, robotics, and autonomous vehicles. YOLO differs from traditional object detection algorithms by framing object detection as a regression problem, predicting bounding box coordinates and class probabilities directly from the input image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb886d15",
   "metadata": {},
   "source": [
    "# 4. What you understand by Hyperparameter Tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6873ef",
   "metadata": {},
   "source": [
    "Hyperparameters are configuration variables that are set before the training process of a model begins. They control the \n",
    "learning process itself, rather than being learned from the data. Hyperparameters are often used to tune the performance \n",
    "of a model, and they can have a significant impact on the model’s accuracy, generalization, and other metrics. Hyperparameters \n",
    "are settings that control the learning process of the model, such as the learning rate, the number of neurons in a neural \n",
    "network etc. \n",
    "\n",
    "Example: Hyperparameters in Neural Network\n",
    "Hyperparameters in Neural Networks\n",
    "1. Learning rate\n",
    "2. Epochs\n",
    "3. Number of layers\n",
    "4. Number of nodes per layer\n",
    "5. Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99baa42",
   "metadata": {},
   "source": [
    "# 5. What you understand by Ensemble Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bacae16",
   "metadata": {},
   "source": [
    "Ensemble learning is a general approach to machine learning that seeks better predictive performance by combining the \n",
    "predictions from multiple models. Ensemble learning refers to a collection of methods that learn a target function by \n",
    "training a number of individual learners and combining their predictions together.\n",
    "\n",
    "Example:\n",
    "Random forest Algorithms:\n",
    "Random Forest algorithm is a supervised learning algorithm. There is a direct relationship between the number of trees \n",
    "in the forest and the results it can get. It uses a number of decision trees and predicts the more accurate result by \n",
    "averaging in case of regression and voting in case of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef149b4e",
   "metadata": {},
   "source": [
    "# 6. What do you understand by Model Evaluation and Selection ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09dad09",
   "metadata": {},
   "source": [
    "For building a model, after doing all EDA and data prprocessing steps we splits that data as train and test and fits to a model\n",
    "by selecting each algorithms. Trying each algorithm is a part of model selection and finalizing the best fit model is chosen by \n",
    "the evaluation process which is called model evaluation. For example, if we are building a classification model then, we \n",
    "evaluate the accuracy to check the performance. likewise in the case of regression model, we evaluate the metrics mae, mse, \n",
    "rmse etc. to understand the performance. By means of model evalaution, model selection is finalized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29509b06",
   "metadata": {},
   "source": [
    "# 7. What you understand by Feature Engineering and Feature selection? What is the difference between them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d5435",
   "metadata": {},
   "source": [
    "Feature Engineering:\n",
    "Feature engineering involves creating new features or modifying existing features in your dataset to improve the \n",
    "performance of machine learning models. It is the process of selecting, transforming, or creating features.\n",
    "\n",
    "It includes,\n",
    "1. Handling missing values\n",
    "2. Encoding\n",
    "3. Scaling etc.\n",
    "\n",
    "Feature selection involves choosing a subset of relevant features from the original set of features to build a model. \n",
    "The goal is to reduce the dimensionality of the feature space by selecting the most informative and important features \n",
    "while eliminating irrelevant or redundant ones.\n",
    "\n",
    "It includes,\n",
    "1. Extracting relevant features\n",
    "2. Dropping unnecessary features\n",
    "3. Dropping features with huge amount of missing values  etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856a72d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
